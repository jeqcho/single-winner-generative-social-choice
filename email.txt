Potential Experiment Setup
We started with talking about the email thread (summarized below). Based on this discussion, Shirley and I proposed the following experiment set-up:

1. Have 10 individuals (or ChatGPT personas) each give a statement on a specific topic

2. Generate 10 summaries of the original statements. These would most likely be generated by AI (for example, by prompting the AI to give a different summary that could be written by each of the original 10 participants)

3. Get voter feedback on the 10 summaries and output a single summary that is in the PVC.

One way to think about this experiment is that we have 10 members of a town's city counsel that want to put out a statement about littering (or 10 members of a Harvard board that want to put out a statement about campus protests). Then each person gives their opinions and there is a discussion, and after the discussion each person summarizes the discussion as well as they can. Then the goal is to choose a single statement out of all of the summaries. The advantage of this approach is that the original topic could be polarizing or not, but the summaries themselves should all be reasonable alternatives.

While technically steps 1 and 3 are what we would get from real people, we can simulate all three steps using ChatGPT, for example as Shirley did here: https://chatgpt.com/share/e/690bb4d7-48a4-8002-acb4-e9904ea5bbb8

Potential Experiment Evaluation

We talked mainly about two forms of evaluation:

1. Compare whether other methods also output elements of the PVC. This could be other voting rules or it could be ChatGPT choosing one of the 10 statements. Then the conclusion based on this experiment could either be "ChatGPT frequently chooses an element of the PVC, so AI is actually pretty good at finding a bridging statement in this set-up" or "ChatGPT frequently did not choose an element of the PVC, so we shouldn't just rely on AI for bridging". 

2. Try to actually evaluate whether participants think that the chosen statement from the PVC is actually a good "consensus/bridging statement". This would probably involve asking new participants whether they think the PVC statement or some "other statement" are better at bridging. If the number of original statements is small enough, then we could even include the original 10 statements as context when we do this evaluation. I think we all still had some reservations about this approach, as this feels more like a question of human psychology than a social choice question.

Next Project Steps
As a next step of the project, I think it would be great if we could start running some end-to-end experiments like Shirley's above on some different topics using purely synthetic ChatGPT data. We can then even try both forms of evaluation above and see what initial results could look like. So to start with, if we could start with a automated pipeline that 
1. Generates (AI generated) 10 statements from a diverse population
2. Generates summaries of the 10 statements from each participants perspective
3. Has each (AI) participant rank the 10 summaries
4. Find the PVC based on these rankings
5. Evaluate other methods on the summaries from step 2, such as having ChatGPT choose one, using Borda Count, etc.

It would then be great to run this pipeline for a variety of topics and see how often the different methods choose elements of the PVC.